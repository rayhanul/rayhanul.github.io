---
layout: default
title: News
---
# News

<!-- Talk at [PPI Industry-University Collaborative Research Center](https://www.ppicenter.org) - 2020 ([slides](https://github.com/maldil/maldil.github.io/blob/master/slides/PPI2020.pptx))<br>
Talk at ICST-2016 [Sensor platform for non-invasive ubiquitous current sensing](https://ieeexplore.ieee.org/abstract/document/7796322)  | China Nanjing (slides) -->
## July 10, 2024

My paper titled: **Analysis of the Effects of Perception Inconsistency Among Interacting Vehicles in Partially Observable Environments** has been accepted for publication at the 27th IEEE Intelligent Transportation Systems Conference (ITSC), which will be held in Edmonton, Canada from September 24-27, 2024. 

## February 26, 2024
I defended my final oral defense for MS in Computer Science on February 26, 2024. 

**My Thesis title: Quantifying Safety in the Partially Observable Environment: Application to Autonomous Vehicles**.

**Abstract**: The safety of autonomous systems (vehicles) largely depends on their ability to synthesize policies in a dynamic and uncertain environment. Traditional methods for policy synthesis use formal verification techniques by relying on precise models (such as Markov Chains or Markov Decision Processes) of other agents within the system. However, in the real-world scenario, uncertainty exists in the transition behavior of different agents, which makes it challenging to construct accurate models. This leads to situations of partial observability due to the agent's inability to observe the actual transition dynamics of other agents or environments. Therefore, in the presence of partial observability, agents may build different models of the same agent. Research shows that inconsistencies in the perception of agents regarding other agents' models could make the overall system unsafe.

This research presents an approach to quantify the safety of the overall system in the partially observable environment among interacting heterogeneous agents. Agents consider the behavior of the environment as a set of Markov chains, and each Markov chain describes the possible behavior of the environment or an agent. In order to synthesize policies, the agent constructs a belief environment model to construct the complete system. The findings show that constructing policies without considering the inconsistencies among other agents may make the complete system unsafe. As a result, the complete system fails to satisfy the given specification. Finally, this approach is run on the autonomous vehicle simulator CARLA to support our findings. 

## January 2024
My Final Oral Defense for MS in Computer Science is Scheduled in Spring 2024

